# mnist with different hyper parameters
In this repo, I trained a model on mnist data with different optimizers, loss functions and activation functions and make comparisons between results.

### val accuracy
![val_accuracy](images/val_accuracy.png)
### val accuracy zoomed
![val_accuracy_zoomed](images/val_accuracy_zoomed.png)
### val loss
![val_loss](images/val_loss.png)
### val loss zoomed
![val_loss_zoomed](images/val_loss_zoomed.png)